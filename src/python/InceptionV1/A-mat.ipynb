{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.misc.io import show\n",
    "import lucid.optvis.objectives as objectives\n",
    "import lucid.optvis.param as param\n",
    "import lucid.optvis.render as render\n",
    "import lucid.optvis.transform as transform\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import tqdm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_size = {\n",
    "    'mixed3a': 256,\n",
    "    'mixed3b': 480,\n",
    "    'mixed3b_3x3': 128,\n",
    "    'mixed3b_5x5': 32,\n",
    "    'mixed4a': 508,\n",
    "    'mixed4a_3x3': 96,\n",
    "    'mixed4a_5x5': 16,\n",
    "    'mixed4b': 512,\n",
    "    'mixed4b_3x3': 112,\n",
    "    'mixed4b_5x5': 24,\n",
    "    'mixed4c': 512,\n",
    "    'mixed4c_3x3': 128,\n",
    "    'mixed4c_5x5': 24,\n",
    "    'mixed4d': 528,\n",
    "    'mixed4d_3x3': 144,\n",
    "    'mixed4d_5x5': 32,\n",
    "    'mixed4e': 832,\n",
    "    'mixed4e_3x3': 160,\n",
    "    'mixed4e_5x5': 32,\n",
    "    'mixed5a': 832,\n",
    "    'mixed5a_3x3': 160,\n",
    "    'mixed5a_5x5': 48,\n",
    "    'mixed5b': 1024,\n",
    "    'mixed5b_3x3': 192,\n",
    "    'mixed5b_5x5': 48\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.InceptionV1()\n",
    "googlenet.load_graphdef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto, image_size=224):\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(\n",
    "            bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    feature_set = {\n",
    "        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "        'image/class/label': tf.FixedLenFeature([], tf.int64),\n",
    "        'image/class/synset': tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "  \n",
    "    parsed_features = tf.parse_single_example(example_proto, feature_set)\n",
    "    label = parsed_features['image/class/label']\n",
    "    synset = parsed_features['image/class/synset']\n",
    "    \n",
    "    image = parsed_features['image/encoded']\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize_images(image, tf.constant([image_size, image_size]))\n",
    "    \n",
    "    return image, label, synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_blk(block):\n",
    "    '''\n",
    "    Get block tensor\n",
    "    * input\n",
    "        - block: the name of block (e.g., 'mixed3a', 'mixed3b_3x3')\n",
    "    * output\n",
    "        - t_block: the tensor of the block\n",
    "    '''\n",
    "\n",
    "    # The name of tensor of the given block\n",
    "    block_name = 'import/%s' % block\n",
    "    if ('_' in block) and (block[-2:] != '_w'):\n",
    "        block_name += '_bottleneck'\n",
    "    block_name += ':0'\n",
    "\n",
    "    # Get the tensor\n",
    "    t_block = tf.get_default_graph().get_tensor_by_name(block_name)\n",
    "\n",
    "    return t_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 1000\n",
    "prob_mass_threshold = 0.03\n",
    "batch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_A_mat(blk, prob_mass_threshold):\n",
    "    \n",
    "    filenames = glob.glob('../../../data/tfrec/*')\n",
    "    \n",
    "    A = np.zeros((num_class, blk_size[blk]), dtype=int)\n",
    "    \n",
    "#     with tf.Graph().as_default():\n",
    "        \n",
    "#         dataset = tf.data.TFRecordDataset(filenames)\n",
    "#         dataset = dataset.map(_parse_function)\n",
    "#         dataset = dataset.map(lambda img, lab, syn: (preprocess_input(img), lab, syn))\n",
    "#         dataset = dataset.batch(batch)\n",
    "\n",
    "#         iterator = dataset.make_one_shot_iterator()\n",
    "#         t_preprocessed_images, t_labels, t_synsets = iterator.get_next()\n",
    "\n",
    "#         T = render.import_model(googlenet, t_preprocessed_images, None)\n",
    "#         T('mixed3a')\n",
    "#         tensors = tf.math.reduce_max(get_t_blk(blk), axis=[1, 2])\n",
    "\n",
    "#         progress_counter = 0\n",
    "#         with tf.Session() as sess:\n",
    "#             start = time.time()\n",
    "\n",
    "#             try:\n",
    "#                 with tqdm.tqdm(total=1281167, unit='imgs') as pbar:\n",
    "#                     while(True):\n",
    "#                         progress_counter += 1\n",
    "#                         imgs_acts_max, labels, synsets = sess.run([tensors, t_labels, t_synsets])\n",
    "\n",
    "#                         # no sess.run after this\n",
    "#                         # python code here on out\n",
    "#                         for i in range(imgs_acts_max.shape[0]):\n",
    "\n",
    "#                             top_channels = []\n",
    "#                             working_acts_max = imgs_acts_max[i] / np.sum(imgs_acts_max[i])\n",
    "#                             prob_mass = 0\n",
    "#                             sorted_working_acts_max, sorted_inds = (list(t) for t in zip(*sorted(zip(working_acts_max, list(range(working_acts_max.shape[0]))), reverse=True)))\n",
    "#                             k = 0\n",
    "#                             while prob_mass < prob_mass_threshold:\n",
    "#                                 top_channels.append(sorted_inds[k])\n",
    "#                                 prob_mass += sorted_working_acts_max[k]\n",
    "#                                 k += 1\n",
    "#                             for top_channel in top_channels:\n",
    "#                                 A[labels[i] - 1][top_channel] += 1\n",
    "\n",
    "#                         pbar.update(len(labels))\n",
    "\n",
    "#             except tf.errors.OutOfRangeError:\n",
    "#                 pass\n",
    "\n",
    "#             end = time.time()\n",
    "#             print(end - start)\n",
    "#             print(progress_counter)\n",
    "#             print(progress_counter*batch)\n",
    "\n",
    "    output_path = '../../../data/InceptionV1/summit/A-mat-nc/A-{}-{}.csv'.format(prob_mass_threshold, blk)\n",
    "    np.savetxt(output_path, A, delimiter=',', fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed3a\n",
      "mixed3b\n",
      "mixed3b_3x3\n",
      "mixed3b_5x5\n",
      "mixed4a\n",
      "mixed4a_3x3\n",
      "mixed4a_5x5\n",
      "mixed4b\n",
      "mixed4b_3x3\n",
      "mixed4b_5x5\n",
      "mixed4c\n",
      "mixed4c_3x3\n",
      "mixed4c_5x5\n",
      "mixed4d\n",
      "mixed4d_3x3\n",
      "mixed4d_5x5\n",
      "mixed4e\n",
      "mixed4e_3x3\n",
      "mixed4e_5x5\n",
      "mixed5a\n",
      "mixed5a_3x3\n",
      "mixed5a_5x5\n",
      "mixed5b\n",
      "mixed5b_3x3\n",
      "mixed5b_5x5\n"
     ]
    }
   ],
   "source": [
    "for blk in blk_size:\n",
    "    print(blk)\n",
    "    if ('3x3' not in blk) and ('5x5' not in blk):\n",
    "        continue\n",
    "    gen_A_mat(blk, prob_mass_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_size = {}\n",
    "for layer in LAYERS:\n",
    "    blk_size[layer] = LAYER_SIZE[layer]\n",
    "    blk_size[layer + '_3x3'] = LAYER_BLK_SIZE[layer + '_3x3']\n",
    "    blk_size[layer + '_5x5'] = LAYER_BLK_SIZE[layer + '_5x5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mixed3a': 256,\n",
       " 'mixed3a_3x3': 96,\n",
       " 'mixed3a_5x5': 16,\n",
       " 'mixed3b': 480,\n",
       " 'mixed3b_3x3': 128,\n",
       " 'mixed3b_5x5': 32,\n",
       " 'mixed4a': 508,\n",
       " 'mixed4a_3x3': 96,\n",
       " 'mixed4a_5x5': 16,\n",
       " 'mixed4b': 512,\n",
       " 'mixed4b_3x3': 112,\n",
       " 'mixed4b_5x5': 24,\n",
       " 'mixed4c': 512,\n",
       " 'mixed4c_3x3': 128,\n",
       " 'mixed4c_5x5': 24,\n",
       " 'mixed4d': 528,\n",
       " 'mixed4d_3x3': 144,\n",
       " 'mixed4d_5x5': 32,\n",
       " 'mixed4e': 832,\n",
       " 'mixed4e_3x3': 160,\n",
       " 'mixed4e_5x5': 32,\n",
       " 'mixed5a': 832,\n",
       " 'mixed5a_3x3': 160,\n",
       " 'mixed5a_5x5': 48,\n",
       " 'mixed5b': 1024,\n",
       " 'mixed5b_3x3': 192,\n",
       " 'mixed5b_5x5': 48}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
