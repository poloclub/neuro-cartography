{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "import tensorflow as tf\n",
    "import lucid.optvis.render as render\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from InceptionV1 import InceptionV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = InceptionV1()\n",
    "# model_wrapper.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load A-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../../data/InceptionV1/summit/A-mat-nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {}\n",
    "for blk in model_wrapper.BLKS:\n",
    "    file_path = '{}/A-0.03-{}.csv'.format(dir_path, blk)\n",
    "    A[blk] = np.loadtxt(file_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find important neurons per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class info\n",
    "input_path = '../../../data/imagenet-labels.txt'\n",
    "df = pd.read_csv(input_path, sep='\\t')\n",
    "\n",
    "# Parse class info\n",
    "class_info = {}\n",
    "for synset, tf_label in zip(df['synset'], df['tfrecord_label']):\n",
    "    class_info[int(tf_label) - 1] = synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_neurons = {}\n",
    "num_class = 1000\n",
    "\n",
    "for c in range(num_class):\n",
    "    \n",
    "    important_neurons[class_info[c]] = {}\n",
    "    \n",
    "    for blk in model_wrapper.BLKS:\n",
    "    \n",
    "        num_neurons_to_sample = int(A[blk].shape[-1] * 0.1)\n",
    "        top_neurons = np.argsort(-A[blk][c])[:num_neurons_to_sample]\n",
    "        top_cnts = A[blk][c][top_neurons]\n",
    "        important_neurons[class_info[c]][blk] = [\n",
    "            {'neuron': neuron, 'cnt': cnt}\n",
    "            for neuron, cnt in zip(top_neurons, top_cnts)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'neuron': 36, 'cnt': 1041.0},\n",
       " {'neuron': 759, 'cnt': 836.0},\n",
       " {'neuron': 787, 'cnt': 800.0},\n",
       " {'neuron': 309, 'cnt': 305.0},\n",
       " {'neuron': 585, 'cnt': 218.0}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: kit_fox\n",
    "important_neurons['n02119789']['mixed4e'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find important groups (+ individual neurons) for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load group\n",
    "group_dir_path = '../../../data/InceptionV1/bucket/bucket-all-5-30-0.03'\n",
    "\n",
    "n2g = {}\n",
    "g2n = {}\n",
    "\n",
    "for blk in model_wrapper.BLKS:\n",
    "        \n",
    "    bucket_path = '{}/buckets-{}.json'.format(group_dir_path, blk)\n",
    "    with open(bucket_path, 'r') as f:\n",
    "        bucket_data = json.load(f)\n",
    "        \n",
    "    for g in bucket_data:\n",
    "        \n",
    "        g2n['g-{}-{}'.format(blk, g)] = bucket_data[g]\n",
    "        \n",
    "        for n in bucket_data[g]:\n",
    "            n2g[n] = 'g-{}-{}'.format(blk, g)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find important neurons and groups\n",
    "num_class = 1000\n",
    "important_groups = {}\n",
    "\n",
    "for c in range(num_class):\n",
    "    \n",
    "    synset = class_info[c]\n",
    "    important_groups[synset] = {}\n",
    "    \n",
    "    for blk in important_neurons[synset]:\n",
    "        \n",
    "        important_groups[synset][blk] = {}\n",
    "        group_number = 0\n",
    "        added_group = {}\n",
    "        \n",
    "        for top_neuron_info in important_neurons[synset][blk]:\n",
    "            \n",
    "            n = top_neuron_info['neuron']\n",
    "            cnt = top_neuron_info['cnt']\n",
    "            neuron = '{}-{}'.format(blk, n)\n",
    "            \n",
    "            if neuron in n2g:\n",
    "                g = n2g[neuron]\n",
    "                if g not in added_group:\n",
    "                    \n",
    "                    # Count all\n",
    "                    cnt = 0\n",
    "                    cnt_d = {}\n",
    "                    for member_neuron in g2n[g]:\n",
    "                        idx = int(member_neuron.split('-')[1])\n",
    "                        cnt += A[blk][c, idx]\n",
    "                        if A[blk][c, idx] > 0:\n",
    "                            cnt_d[member_neuron] = A[blk][c, idx]\n",
    "                    \n",
    "                    # Count top-10\n",
    "                    top_neurons = []\n",
    "                    top_cnts = 0\n",
    "                    for nn, cc in sorted(cnt_d.items(), key=lambda x: x[1], reverse=True):\n",
    "                        top_neurons.append(nn)\n",
    "                        top_cnts += cnt_d[nn]\n",
    "                    \n",
    "                    important_groups[synset][blk][group_number] = {\n",
    "                        'group-all': g2n[g],\n",
    "                        'cnt-all': cnt / len(g2n[g]),\n",
    "                        'group': top_neurons[:10],\n",
    "                        'cnt': top_cnts / len(top_neurons[:10]) if len(top_neurons) > 0 else 0\n",
    "                    }\n",
    "                    group_number += 1\n",
    "                    added_group[g] = True\n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                important_groups[synset][blk][group_number] = {\n",
    "                    'group': [neuron],\n",
    "                    'cnt': cnt\n",
    "                }\n",
    "                group_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort important groups by cnt\n",
    "for synset in important_groups:\n",
    "    for blk in important_groups[synset]:\n",
    "        sorted_nodes = sorted(important_groups[synset][blk].items(), key=lambda x: x[1]['cnt'], reverse=True)\n",
    "        only_sorted_nodes = {'g-{}-{}'.format(blk, i): item[1] for i, item in enumerate(sorted_nodes)}\n",
    "        important_groups[synset][blk] = only_sorted_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save important group\n",
    "output_dir_path = '../../../data/InceptionV1/graph/node/'\n",
    "for synset in important_groups:\n",
    "    file_path = '{}/node-{}.json'.format(output_dir_path, synset)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(important_groups[synset], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
